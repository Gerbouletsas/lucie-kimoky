import logging
from typing import List, Dict, Any
from openai import OpenAI

from vector_store import VectorStore

logger = logging.getLogger(__name__)

class ChatHandler:
    def __init__(self, openai_api_key: str, vector_store: VectorStore):
        self.openai_client = OpenAI(api_key=openai_api_key)
        self.vector_store = vector_store
        self.model = "gpt-4o"
        self.temperature = 0.3

        self.system_prompt = """
Tu es **Lucie**, la conseill√®re digitale de la marque Kimoky (https://kimoky.com), une boutique sp√©cialis√©e dans les kimonos modernes, √©l√©gants et inspir√©s de l‚Äôesth√©tique japonaise. Tu accompagnes chaque visiteur avec douceur, pr√©cision et √©l√©gance.

üéØ Ton r√¥le :
1. Guider les clientes et clients dans le choix du kimono id√©al selon leur morphologie, le style recherch√© (chic, nuit, d√©contract√©, plage‚Ä¶), la mati√®re (satin, coton‚Ä¶) ou la saison.
2. R√©pondre de fa√ßon concise, fluide et rassurante √† toutes les questions pratiques : livraison, retours, √©changes, tailles, suivi de commande, s√©curit√©, contact client.

‚ú® Ton ton est toujours :
- po√©tique, chaleureux, professionnel et fluide
- fid√®le √† l‚Äôunivers raffin√© de Kimoky
- orient√© conseil, inspiration et confiance

üìå R√®gles :
- Tu ne donnes **jamais de prix**
- Tu ne passes **jamais commande**
- Tu ne dis **jamais que tu es une IA ou un chatbot**
- Tu restes toujours polie, rassurante et √©l√©gante
- Tu peux proposer des liens utiles vers https://kimoky.com si cela aide

üñãÔ∏è Tu peux utiliser **1 √† 2 emojis √©l√©gants maximum** (ex : ‚ú®, üå∏, üì¶, üíå), uniquement s‚Äôils renforcent la clart√© ou l‚Äô√©motion. Jamais d‚Äôemojis trop familiers (üòçüî•üòÇ‚Ä¶).

üí¨ Si une question est floue, reformule-la avec tact. Si la personne semble perdue, guide-la avec douceur.

üéÅ Exemples de ton :
- ¬´ Ce mod√®le long en satin fluide sublimera les silhouettes √©lanc√©es ‚ú® ¬ª
- ¬´ Vous pouvez suivre votre commande directement sur notre page de suivi üì¶ ¬ª
- ¬´ Pour une soir√©e douce √† la maison, optez pour un kimono mi-long en coton l√©ger. ¬ª

Tu es **Lucie**, la voix √©l√©gante et bienveillante de Kimoky üå∏
        """

    def get_response(self, question: str, is_mobile: bool = False) -> str:
        try:
            context_docs = self.vector_store.search(question, top_k=5)
            context = self._build_context(context_docs)

            if context.strip().startswith("Aucun document"):
                return "Je n‚Äôai pas trouv√© cette information dans notre base. Vous pouvez consulter notre page FAQ ou nous √©crire √† boutique@kimoky.com üíå"

            user_prompt = self._create_user_prompt(question, context)

            response = self.openai_client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=self.temperature,
                max_tokens=400 if is_mobile else 800
            )

            answer = response.choices[0].message.content

            # Supprimer le pr√©fixe [Kimoky] s'il appara√Æt
            if answer.strip().startswith("[Kimoky]"):
                answer = answer.strip().replace("[Kimoky]", "", 1).lstrip()

            logger.info(f"Generated response for question: {question[:50]}...")
            return answer

        except Exception as e:
            logger.error(f"Error generating response: {e}")
            return "Je suis d√©sol√©e, une erreur s‚Äôest produite. N‚Äôh√©sitez pas √† nous recontacter ou √† consulter notre page d‚Äôaide."

    def _build_context(self, context_docs: List[Dict[str, Any]]) -> str:
        if not context_docs:
            return "Aucun document de r√©f√©rence trouv√©."

        context_parts = []
        for i, doc in enumerate(context_docs, 1):
            source = doc.get("source_file", "Document")
            text = doc.get("text", "")
            score = doc.get("similarity_score", 0)
            context_parts.append(f"[Document {i} - {source} (pertinence: {score:.2f})]:\n{text}\n")

        return "\n".join(context_parts)

    def _create_user_prompt(self, question: str, context: str) -> str:
        return f"""QUESTION : {question}

CONTEXTE :
{context}

R√©ponds de fa√ßon concise, chaleureuse et professionnelle, en t‚Äôappuyant sur le contexte si possible. Si le contexte est insuffisant, propose une r√©ponse rassurante ou un lien vers le site Kimoky."""

    def _categorize_question(self, question: str) -> str:
        question_lower = question.lower()
        if any(word in question_lower for word in ["livraison", "exp√©dition", "d√©lai", "transport"]):
            return "livraison"
        elif any(word in question_lower for word in ["retour", "√©change", "remboursement", "cgv"]):
            return "retours"
        elif any(word in question_lower for word in ["taille", "sizing", "mesure", "morphologie"]):
            return "taille"
        elif any(word in question_lower for word in ["mati√®re", "composition", "entretien", "lavage"]):
            return "produit"
        else:
            return "general"
